{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lstm.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1do92brMqWPfhHJ1reNRwoJyko0QNGuoY",
      "authorship_tag": "ABX9TyNXoli9n74hmAj/auJtb9Rv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/itsSrijan/whatsapp-chat-analysis/blob/main/lstm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install keras-tuner"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "awNo0_jtCrbn",
        "outputId": "c9f90edb-44e0-48db-9b96-0cc25282ce82"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting keras-tuner\n",
            "  Downloading keras_tuner-1.1.2-py3-none-any.whl (133 kB)\n",
            "\u001b[K     |████████████████████████████████| 133 kB 7.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: ipython in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (5.5.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (1.21.6)\n",
            "Collecting kt-legacy\n",
            "  Downloading kt_legacy-1.0.4-py3-none-any.whl (9.6 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (2.23.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (21.3)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (2.8.0)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (5.1.1)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (1.0.18)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (4.8.0)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (0.7.5)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (4.4.2)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (57.4.0)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (0.8.1)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (2.6.1)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->keras-tuner) (1.15.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->keras-tuner) (0.2.5)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->keras-tuner) (3.0.9)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect->ipython->keras-tuner) (0.7.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner) (2022.5.18.1)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (1.1.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (3.3.7)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (1.35.0)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (1.46.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (0.4.6)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (0.37.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (1.8.1)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (3.17.3)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (0.6.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->keras-tuner) (4.8)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->keras-tuner) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->keras-tuner) (4.2.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->keras-tuner) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard->keras-tuner) (4.11.4)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard->keras-tuner) (4.2.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard->keras-tuner) (3.8.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->keras-tuner) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->keras-tuner) (3.2.0)\n",
            "Installing collected packages: kt-legacy, keras-tuner\n",
            "Successfully installed keras-tuner-1.1.2 kt-legacy-1.0.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "CFtRvZSm53-e"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import copy\n",
        "import itertools\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import keras_tuner as kt\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import InputLayer, LSTM\n",
        "from tensorflow.keras.layers import BatchNormalization, Activation, GlobalMaxPooling1D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.metrics import binary_crossentropy\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from keras_tuner.tuners import RandomSearch, Hyperband\n",
        "# from keras.wrappers.scikit_learn import KerasClassifier\n",
        "# from sklearn.model_selection import RandomizedSearchCV\n",
        "# from scikeras.wrappers import KerasClassifier\n",
        "# from sklearn.metrics import roc_auc_score, accuracy_score, confusion_matrix, roc_curve, classification_report\n",
        "\n",
        "mpl.rcParams['figure.figsize'] = (12,8)\n",
        "mpl.rcParams['axes.grid'] = False"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Can be provided separetely\n",
        "\n",
        "* Inputs\n",
        "1. no. of samples in each frame = ns\n",
        "2. joints/accelerometer which onw wants to analyse = j\n",
        "3. filters = f1, f2\n",
        "4. kernel_size = k\n",
        "5. strides = s\n",
        "6. learning_rate = lr\n",
        "7. validation_split = vs\n",
        "8. batch_size = b\n",
        "9. epochs = e  \n",
        "\n",
        "* Functions\n",
        "1. takes **ns, j, (directory)** and returns **scaled_train, train_label, scaled_test, test_label**\n",
        "2. takes \n",
        "3. takes **f, k, lr, s** and returns **model**\n",
        " "
      ],
      "metadata": {
        "id": "X8LljruGuAE6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Inputs\n",
        "\n",
        "directory = '/content/drive/MyDrive/Dataset'\n",
        "sampling_freq = 1024\n",
        "duration = 256\n",
        "nojoints = 30\n",
        "nosamples = 64 #nosamples = [64, 128, 256, 512]\n",
        "timesteps = 8\n",
        "# strides = 1\n",
        "# learning_rate = 0.001\n",
        "# batch_size = 32\n",
        "epochs = 100\n",
        "# validation_split = 0.1\n",
        "\n",
        "frames = (sampling_freq * duration)/(nosamples * timesteps)"
      ],
      "metadata": {
        "id": "tjLyxrtUOU8W"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "frames"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GJSovwc3piK1",
        "outputId": "1a9170f5-4d1f-4522-fb67-42aca0d166b6"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "512.0"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#here, we are reading the different .csv from the directory which contain the data\n",
        "\n",
        "i = 0\n",
        "DF = {} #this will contain the damaged frames for all joint\n",
        "UFN = {} #this will contain undamaged shuffled frames for all joints joint\n",
        "for filename in os.scandir(directory):\n",
        "     if filename.is_file():\n",
        "        i = i + 1 \n",
        "        df = pd.read_csv(filename.path)\n",
        "        if str(i) in filename.name:\n",
        "            col = 'J' + str(i)\n",
        "            key = 'DF'+ str(i)\n",
        "            DF[key] = df[col] \n",
        "        for j in range(1, nojoints + 1):\n",
        "            if j!=i:\n",
        "              col = 'J' + str(j)\n",
        "              key_UFN = 'UFN' + str(j)\n",
        "              if key_UFN not in UFN:\n",
        "                UFN[key_UFN] = []\n",
        "              UFN[key_UFN].append(df[col])\n",
        "\n",
        "for keys in DF:\n",
        "  temp1 = np.array(DF[keys])\n",
        "  temp2 = np.array(np.split(temp1,sampling_freq * duration / nosamples)) #splitting damaged dataset into frames\n",
        "  DF[keys] = np.array(np.split(temp2, frames))\n",
        "\n",
        "for keys in UFN:\n",
        "  temp1 = np.array(UFN[keys])\n",
        "  temp2 = np.reshape(temp1, temp1.shape[0] * temp1.shape[1])\n",
        "  temp3 = np.array(np.split(temp2, sampling_freq * duration * nojoints / nosamples)) #splitting undamaged dataset into frames, each having 128 samples\n",
        "  temp4 = np.array(np.split(temp3, temp3.shape[0] / timesteps))\n",
        "  np.random.shuffle(temp4) #shuffling the undamaged frames\n",
        "  UFN[keys] = temp4   #[:int(frames),:] #selecting first 'n' frames equal to no. of damaged frames"
      ],
      "metadata": {
        "id": "YDhZONIk-h49"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y1 = copy.deepcopy(UFN['UFN1'])\n",
        "y2 = copy.deepcopy(DF['DF1'])\n",
        "\n",
        "\n",
        "y1_label = np.zeros((y1.shape[0], 1))\n",
        "y2_label = np.ones((y2.shape[0], 1))\n",
        "# one_hot_label = to_categorical(input_labels)\n",
        "\n",
        "# now, y1 contains 4096 undamaged frames and y2 contains 4096 damaged frames. In the paper, half of the frames from both undamaged and \n",
        "# damaged was used for training. \n",
        "\n",
        "# we will take 10% of from half of damaged and half of undamaged frames to create a validation set\n",
        "\n",
        " \n",
        "\n",
        "\n",
        "y1_half = y1[:int(frames/2)]\n",
        "y2_half = y2[:int(frames/2)]\n",
        "y1_label_half = y1_label[:int(frames/2)]\n",
        "y2_label_half = y2_label[:int(frames/2)]\n",
        "train = np.concatenate((y1_half, y2_half), axis = 0)\n",
        "train_label = np.concatenate((y1_label_half, y2_label_half), axis = 0)\n",
        "train_label = np.reshape(train_label, (train_label.shape[0], 1))\n",
        "train_label = to_categorical(train_label)\n",
        "train, train_label = shuffle (train, train_label, random_state = 42)\n",
        "\n",
        "# Here, we are using the remaining half for test purpose\n",
        "\n",
        "y1_rem = y1[int(frames/2):int(frames)]\n",
        "y2_rem = y2[int(frames/2):int(frames)]\n",
        "y1_label_rem = y1_label[int(frames/2):int(frames)]\n",
        "y2_label_rem = y2_label[int(frames/2):int(frames)]\n",
        "test = np.concatenate((y1_rem, y2_rem), axis = 0)\n",
        "test_label = np.concatenate((y1_label_rem, y2_label_rem), axis = 0)\n",
        "test_label = np.reshape(test_label, (test_label.shape[0], 1))\n",
        "test_label = to_categorical(test_label)\n",
        "test, test_label = shuffle(test, test_label, random_state = 42)\n"
      ],
      "metadata": {
        "id": "zFP5DdUiCRbb"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# scaling the training and test data\n",
        "\n",
        "scaler = StandardScaler()\n",
        "scaled_train = scaler.fit_transform(train.reshape(-1, train.shape[-1])).reshape(train.shape)\n",
        "scaled_test = scaler.transform(test.reshape(-1, test.shape[-1])).reshape(test.shape)"
      ],
      "metadata": {
        "id": "tYebeu5UDjUX"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train_generator = TimeseriesGenerator(scaled_train, train_label, length = timesteps, stride = timesteps, batch_size = 1,sampling_rate = 1)\n",
        "# test_generator = TimeseriesGenerator(scaled_test, test_label, length = timesteps, stride = timesteps, batch_size = 1, sampling_rate = 1)"
      ],
      "metadata": {
        "id": "N8ge8R19zasC"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def LSTM_classifier():\n",
        "\n",
        "#   model = Sequential()\n",
        "#   model.add(LSTM(units = 64 , activation='tanh', input_shape=(timesteps, nosamples), return_sequences=True))\n",
        "#   model.add(Dropout(rate = 0.2))\n",
        "#   model.add(LSTM(units = 128, activation='tanh', return_sequences=True))\n",
        "#   model.add(Dropout(rate = 0.2))\n",
        "#   model.add(LSTM(units = 64, activation='tanh', return_sequences=False))\n",
        "#   model.add(Dropout(rate = 0.2))\n",
        "#   model.add(Flatten())\n",
        "#   model.add(Dense(units = 32))\n",
        "#   model.add(Dropout(rate = 0.2))\n",
        "#   model.add(Dense(units = 2, activation = 'softmax'))\n",
        "#   model.compile(optimizer = Adam(learning_rate = learning_rate), loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
        "#   return model\n",
        "\n"
      ],
      "metadata": {
        "id": "Cji8KxD4F4MD"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # timesteps = [2, 4, 8, 16] timesteps = timesteps,\n",
        "# # nolayers = [1, 2, 3, 4, 5, 6] nolayers = nolayers\n",
        "# units = [1024, 512, 256, 128, 64, 32]\n",
        "# rate = [0.2, 0.5]\n",
        "# learning_rate = [0.0003, 0.001, 0.01]\n",
        "# batch_size = [64, 256, 512]\n",
        "# nodes = (\n",
        "#     list(itertools.product(units, repeat=1))\n",
        "#     + list(itertools.product(units, repeat=2))\n",
        "#     + list(itertools.product(units, repeat=3))\n",
        "#     + list(itertools.product(units, repeat=4))\n",
        "#     + list(itertools.product(units, repeat=5))\n",
        "#     + list(itertools.product(units, repeat=6))\n",
        "# )\n",
        "\n",
        "# param_grid = dict(  nodes = nodes, rate = rate, learning_rate = learning_rate, batch_size = batch_size, units = units)"
      ],
      "metadata": {
        "id": "iN_dQIApnlvO"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def build_model(hp):\n",
        "#   model = keras.Sequential()\n",
        "#   model.add(InputLayer(input_shape = (8,64)))\n",
        "#   for i in range(hp.Int('layers', 1, 6)): \n",
        "#       model.add(LSTM(units = hp.Int('units' + str(i+1), 32, 1024, 32), activation = 'tanh', return_sequences = True, dropout = hp.Choice('rate' + str(i+1), [0.2, 0.5], ordered = False)))\n",
        "#   model.add(Flatten())\n",
        "#   model.add(Dense(units = hp.Choice('units', [16, 32, 64], ordered = False)))\n",
        "#   model.add(Dropout(rate = hp.Choice('rate', [0.2, 0.5], ordered = False)))\n",
        "#   model.add(Dense(units = 2, activation='softmax'))\n",
        "\n",
        "#   model.compile(optimizer = Adam(learning_rate = hp.Choice('learning_rate', [0.0003, 0.001, 0.01], ordered = False)), loss='binary_crossentropy', metrics = ['accuracy'])\n",
        "#   return model\n"
      ],
      "metadata": {
        "id": "AUIGonxIFmyL"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MyHyperModel(kt.HyperModel):\n",
        "  def build(self, hp):\n",
        "    model = keras.Sequential()\n",
        "    model.add(InputLayer(input_shape = (8,64)))\n",
        "    for i in range(hp.Int('layers', 1, 6)): \n",
        "      model.add(LSTM(units = hp.Choice('units' + str(i+1),  [32, 64, 128, 512, 1024], ordered = False, default = 32), activation = 'tanh', return_sequences = True))\n",
        "      model.add(Dropout(rate = hp.Float('rate' + str(i+1), 0.1, 0.2, 0.05)))\n",
        "    model.add(Flatten())\n",
        "    # model.add(Dropout(rate = hp.Float('rate', 0.1, 0.2, 0.05 )))\n",
        "    model.add(Dense(units = hp.Choice('units', [8, 16, 32, 64], ordered = False)))\n",
        "    \n",
        "    model.add(Dense(units = 2, activation='softmax'))\n",
        "\n",
        "    model.compile(optimizer = Adam(learning_rate = hp.Choice('learning_rate', [0.0003, 0.001, 0.01], ordered = False)), loss='binary_crossentropy', metrics = ['accuracy'])\n",
        "    return model\n",
        "\n",
        "  def fit_it(self, hp, model, x, y, validation_split, callbacks=None, *args, **kwargs):\n",
        "    return model.fit(x, y, validation_split, batch_size = hp.Choice('batch_size', [64, 256, 512], ordered = False), verbose = 2, *args, **kwargs,)"
      ],
      "metadata": {
        "id": "rMB4oWY02ke1"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tuner = RandomSearch(\n",
        "    MyHyperModel(), \n",
        "    objective ='val_accuracy', \n",
        "    max_trials = 20, \n",
        "    executions_per_trial = 3,\n",
        "    directory = '/content/drive/MyDrive/Colab Notebooks', \n",
        "    project_name = 'tuner12_with_callback',)"
      ],
      "metadata": {
        "id": "FfsyydgmZHJv"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "early_stopping = EarlyStopping(monitor='val_accuracy', \n",
        "    patience=2, \n",
        "    min_delta=0.005, \n",
        "    mode='max')"
      ],
      "metadata": {
        "id": "UAabA8dhJKOm"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tuner.search_space_summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2m371j-1c8v7",
        "outputId": "40c855b5-8f4e-4e0c-ae73-4733991141cb"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Search space summary\n",
            "Default search space size: 5\n",
            "layers (Int)\n",
            "{'default': None, 'conditions': [], 'min_value': 1, 'max_value': 6, 'step': 1, 'sampling': None}\n",
            "units1 (Choice)\n",
            "{'default': 32, 'conditions': [], 'values': [32, 64, 128, 512, 1024], 'ordered': False}\n",
            "rate1 (Float)\n",
            "{'default': 0.1, 'conditions': [], 'min_value': 0.1, 'max_value': 0.2, 'step': 0.05, 'sampling': None}\n",
            "units (Choice)\n",
            "{'default': 8, 'conditions': [], 'values': [8, 16, 32, 64], 'ordered': False}\n",
            "learning_rate (Choice)\n",
            "{'default': 0.0003, 'conditions': [], 'values': [0.0003, 0.001, 0.01], 'ordered': False}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tuner.search(scaled_train, train_label, validation_split = 0.2, epochs = 30, callbacks = [early_stopping])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IwRbkDhudQET",
        "outputId": "db307177-4d04-4468-e86f-61e26b7f49c0"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 20 Complete [00h 00m 39s]\n",
            "val_accuracy: 0.9352750778198242\n",
            "\n",
            "Best val_accuracy So Far: 0.9805825153986613\n",
            "Total elapsed time: 00h 11m 14s\n",
            "INFO:tensorflow:Oracle triggered exit\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tuner.results_summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dLYFh-fszXv_",
        "outputId": "a5a1652f-e6d7-415b-c13f-835d65d82efc"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results summary\n",
            "Results in /content/drive/MyDrive/Colab Notebooks/tuner12_with_callback\n",
            "Showing 10 best trials\n",
            "<keras_tuner.engine.objective.Objective object at 0x7f2470c76110>\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "layers: 2\n",
            "units1: 128\n",
            "rate1: 0.1\n",
            "units: 8\n",
            "learning_rate: 0.01\n",
            "units2: 32\n",
            "rate2: 0.1\n",
            "units3: 1024\n",
            "rate3: 0.15000000000000002\n",
            "units4: 64\n",
            "rate4: 0.20000000000000004\n",
            "units5: 64\n",
            "rate5: 0.1\n",
            "Score: 0.9805825153986613\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "layers: 2\n",
            "units1: 32\n",
            "rate1: 0.20000000000000004\n",
            "units: 16\n",
            "learning_rate: 0.01\n",
            "units2: 32\n",
            "rate2: 0.1\n",
            "Score: 0.9773462812105814\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "layers: 1\n",
            "units1: 32\n",
            "rate1: 0.15000000000000002\n",
            "units: 64\n",
            "learning_rate: 0.001\n",
            "units2: 128\n",
            "rate2: 0.20000000000000004\n",
            "units3: 128\n",
            "rate3: 0.1\n",
            "units4: 32\n",
            "rate4: 0.20000000000000004\n",
            "units5: 1024\n",
            "rate5: 0.15000000000000002\n",
            "Score: 0.9741100271542867\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "layers: 1\n",
            "units1: 1024\n",
            "rate1: 0.20000000000000004\n",
            "units: 64\n",
            "learning_rate: 0.0003\n",
            "units2: 512\n",
            "rate2: 0.15000000000000002\n",
            "units3: 512\n",
            "rate3: 0.15000000000000002\n",
            "units4: 128\n",
            "rate4: 0.20000000000000004\n",
            "units5: 64\n",
            "rate5: 0.1\n",
            "Score: 0.9676375389099121\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "layers: 3\n",
            "units1: 64\n",
            "rate1: 0.20000000000000004\n",
            "units: 64\n",
            "learning_rate: 0.001\n",
            "units2: 64\n",
            "rate2: 0.1\n",
            "units3: 64\n",
            "rate3: 0.15000000000000002\n",
            "units4: 1024\n",
            "rate4: 0.15000000000000002\n",
            "units5: 32\n",
            "rate5: 0.20000000000000004\n",
            "Score: 0.9611650506655375\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "layers: 6\n",
            "units1: 128\n",
            "rate1: 0.15000000000000002\n",
            "units: 32\n",
            "learning_rate: 0.001\n",
            "units2: 128\n",
            "rate2: 0.15000000000000002\n",
            "units3: 32\n",
            "rate3: 0.20000000000000004\n",
            "units4: 128\n",
            "rate4: 0.15000000000000002\n",
            "units5: 512\n",
            "rate5: 0.15000000000000002\n",
            "units6: 32\n",
            "rate6: 0.1\n",
            "Score: 0.9611650506655375\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "layers: 4\n",
            "units1: 512\n",
            "rate1: 0.20000000000000004\n",
            "units: 16\n",
            "learning_rate: 0.001\n",
            "units2: 32\n",
            "rate2: 0.20000000000000004\n",
            "units3: 512\n",
            "rate3: 0.20000000000000004\n",
            "units4: 1024\n",
            "rate4: 0.20000000000000004\n",
            "units5: 512\n",
            "rate5: 0.20000000000000004\n",
            "units6: 32\n",
            "rate6: 0.20000000000000004\n",
            "Score: 0.9611650506655375\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "layers: 5\n",
            "units1: 64\n",
            "rate1: 0.1\n",
            "units: 64\n",
            "learning_rate: 0.001\n",
            "units2: 512\n",
            "rate2: 0.15000000000000002\n",
            "units3: 64\n",
            "rate3: 0.20000000000000004\n",
            "units4: 64\n",
            "rate4: 0.15000000000000002\n",
            "units5: 64\n",
            "rate5: 0.15000000000000002\n",
            "units6: 512\n",
            "rate6: 0.15000000000000002\n",
            "Score: 0.9579287966092428\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "layers: 5\n",
            "units1: 512\n",
            "rate1: 0.15000000000000002\n",
            "units: 8\n",
            "learning_rate: 0.001\n",
            "units2: 32\n",
            "rate2: 0.1\n",
            "units3: 32\n",
            "rate3: 0.15000000000000002\n",
            "units4: 64\n",
            "rate4: 0.1\n",
            "units5: 1024\n",
            "rate5: 0.1\n",
            "Score: 0.954692562421163\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "layers: 2\n",
            "units1: 1024\n",
            "rate1: 0.15000000000000002\n",
            "units: 16\n",
            "learning_rate: 0.0003\n",
            "units2: 128\n",
            "rate2: 0.20000000000000004\n",
            "Score: 0.9449838201204935\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_params = tuner.get_best_hyperparameters(num_trials = 1)[0]\n",
        "best_params.values"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8YS0BXC-XNpi",
        "outputId": "edb75736-0e9e-49c1-a68a-dcbc8ec717f0"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'layers': 2,\n",
              " 'learning_rate': 0.01,\n",
              " 'rate1': 0.1,\n",
              " 'rate2': 0.1,\n",
              " 'rate3': 0.15000000000000002,\n",
              " 'rate4': 0.20000000000000004,\n",
              " 'rate5': 0.1,\n",
              " 'units': 8,\n",
              " 'units1': 128,\n",
              " 'units2': 32,\n",
              " 'units3': 1024,\n",
              " 'units4': 64,\n",
              " 'units5': 64}"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tuner.get_best_models(num_models = 1)[0].summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IG2TW5-eYIm4",
        "outputId": "1693b5f4-f1da-43ca-fdda-6e4125764ca0"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm (LSTM)                 (None, 8, 128)            98816     \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 8, 128)            0         \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 8, 32)             20608     \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 8, 32)             0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 256)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 8)                 2056      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 2)                 18        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 121,498\n",
            "Trainable params: 121,498\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.iter\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.beta_1\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.beta_2\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.decay\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.learning_rate\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = tuner.hypermodel.build(best_params)\n",
        "history = model.fit(scaled_train, train_label, epochs=50, validation_split=0.2)\n",
        "\n",
        "val_acc_per_epoch = history.history['val_accuracy']\n",
        "best_epoch = val_acc_per_epoch.index(max(val_acc_per_epoch)) + 1\n",
        "print('Best epoch: %d' % (best_epoch))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CkrM5yXXYpaw",
        "outputId": "3b3a3bad-ea4f-4810-e7af-8a2b5d215858"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "13/13 [==============================] - 4s 68ms/step - loss: 0.4508 - accuracy: 0.7946 - val_loss: 0.3675 - val_accuracy: 0.8447\n",
            "Epoch 2/50\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0932 - accuracy: 0.9780 - val_loss: 0.2537 - val_accuracy: 0.9126\n",
            "Epoch 3/50\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 0.0967 - accuracy: 0.9731 - val_loss: 0.0803 - val_accuracy: 0.9612\n",
            "Epoch 4/50\n",
            "13/13 [==============================] - 0s 10ms/step - loss: 8.1378e-04 - accuracy: 1.0000 - val_loss: 0.1227 - val_accuracy: 0.9709\n",
            "Epoch 5/50\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 3.3188e-04 - accuracy: 1.0000 - val_loss: 0.0913 - val_accuracy: 0.9709\n",
            "Epoch 6/50\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 1.1432e-05 - accuracy: 1.0000 - val_loss: 0.0738 - val_accuracy: 0.9806\n",
            "Epoch 7/50\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 7.7893e-06 - accuracy: 1.0000 - val_loss: 0.0711 - val_accuracy: 0.9806\n",
            "Epoch 8/50\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 4.5783e-06 - accuracy: 1.0000 - val_loss: 0.0709 - val_accuracy: 0.9806\n",
            "Epoch 9/50\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 3.6517e-06 - accuracy: 1.0000 - val_loss: 0.0703 - val_accuracy: 0.9806\n",
            "Epoch 10/50\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 2.6133e-06 - accuracy: 1.0000 - val_loss: 0.0701 - val_accuracy: 0.9806\n",
            "Epoch 11/50\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 3.9008e-06 - accuracy: 1.0000 - val_loss: 0.0697 - val_accuracy: 0.9806\n",
            "Epoch 12/50\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 3.1118e-06 - accuracy: 1.0000 - val_loss: 0.0694 - val_accuracy: 0.9806\n",
            "Epoch 13/50\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 2.1402e-06 - accuracy: 1.0000 - val_loss: 0.0690 - val_accuracy: 0.9806\n",
            "Epoch 14/50\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 2.5073e-06 - accuracy: 1.0000 - val_loss: 0.0686 - val_accuracy: 0.9806\n",
            "Epoch 15/50\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 1.9084e-06 - accuracy: 1.0000 - val_loss: 0.0684 - val_accuracy: 0.9806\n",
            "Epoch 16/50\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 3.1430e-06 - accuracy: 1.0000 - val_loss: 0.0681 - val_accuracy: 0.9806\n",
            "Epoch 17/50\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 2.2863e-06 - accuracy: 1.0000 - val_loss: 0.0679 - val_accuracy: 0.9806\n",
            "Epoch 18/50\n",
            "13/13 [==============================] - 0s 10ms/step - loss: 2.1921e-06 - accuracy: 1.0000 - val_loss: 0.0677 - val_accuracy: 0.9806\n",
            "Epoch 19/50\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 2.4869e-06 - accuracy: 1.0000 - val_loss: 0.0677 - val_accuracy: 0.9806\n",
            "Epoch 20/50\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 1.6455e-06 - accuracy: 1.0000 - val_loss: 0.0676 - val_accuracy: 0.9806\n",
            "Epoch 21/50\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 1.8236e-06 - accuracy: 1.0000 - val_loss: 0.0673 - val_accuracy: 0.9806\n",
            "Epoch 22/50\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 1.8022e-06 - accuracy: 1.0000 - val_loss: 0.0670 - val_accuracy: 0.9806\n",
            "Epoch 23/50\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 2.2727e-06 - accuracy: 1.0000 - val_loss: 0.0668 - val_accuracy: 0.9806\n",
            "Epoch 24/50\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 1.6433e-06 - accuracy: 1.0000 - val_loss: 0.0662 - val_accuracy: 0.9806\n",
            "Epoch 25/50\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 2.6031e-06 - accuracy: 1.0000 - val_loss: 0.0660 - val_accuracy: 0.9806\n",
            "Epoch 26/50\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 1.4675e-06 - accuracy: 1.0000 - val_loss: 0.0657 - val_accuracy: 0.9806\n",
            "Epoch 27/50\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 1.6461e-06 - accuracy: 1.0000 - val_loss: 0.0656 - val_accuracy: 0.9806\n",
            "Epoch 28/50\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 1.4563e-06 - accuracy: 1.0000 - val_loss: 0.0652 - val_accuracy: 0.9806\n",
            "Epoch 29/50\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 1.2569e-06 - accuracy: 1.0000 - val_loss: 0.0648 - val_accuracy: 0.9806\n",
            "Epoch 30/50\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 1.4427e-06 - accuracy: 1.0000 - val_loss: 0.0646 - val_accuracy: 0.9806\n",
            "Epoch 31/50\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 1.6245e-06 - accuracy: 1.0000 - val_loss: 0.0643 - val_accuracy: 0.9806\n",
            "Epoch 32/50\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 1.4070e-06 - accuracy: 1.0000 - val_loss: 0.0641 - val_accuracy: 0.9806\n",
            "Epoch 33/50\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 1.4150e-06 - accuracy: 1.0000 - val_loss: 0.0639 - val_accuracy: 0.9806\n",
            "Epoch 34/50\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 1.3584e-06 - accuracy: 1.0000 - val_loss: 0.0636 - val_accuracy: 0.9806\n",
            "Epoch 35/50\n",
            "13/13 [==============================] - 0s 10ms/step - loss: 1.5188e-06 - accuracy: 1.0000 - val_loss: 0.0636 - val_accuracy: 0.9806\n",
            "Epoch 36/50\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 1.2855e-06 - accuracy: 1.0000 - val_loss: 0.0635 - val_accuracy: 0.9806\n",
            "Epoch 37/50\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 1.2379e-06 - accuracy: 1.0000 - val_loss: 0.0634 - val_accuracy: 0.9806\n",
            "Epoch 38/50\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 1.0426e-06 - accuracy: 1.0000 - val_loss: 0.0632 - val_accuracy: 0.9806\n",
            "Epoch 39/50\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 1.3465e-06 - accuracy: 1.0000 - val_loss: 0.0629 - val_accuracy: 0.9806\n",
            "Epoch 40/50\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 1.1765e-06 - accuracy: 1.0000 - val_loss: 0.0627 - val_accuracy: 0.9806\n",
            "Epoch 41/50\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 1.1758e-06 - accuracy: 1.0000 - val_loss: 0.0625 - val_accuracy: 0.9806\n",
            "Epoch 42/50\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 1.6389e-06 - accuracy: 1.0000 - val_loss: 0.0632 - val_accuracy: 0.9806\n",
            "Epoch 43/50\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 1.0391e-06 - accuracy: 1.0000 - val_loss: 0.0632 - val_accuracy: 0.9806\n",
            "Epoch 44/50\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 1.0890e-06 - accuracy: 1.0000 - val_loss: 0.0630 - val_accuracy: 0.9806\n",
            "Epoch 45/50\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 1.5176e-06 - accuracy: 1.0000 - val_loss: 0.0631 - val_accuracy: 0.9806\n",
            "Epoch 46/50\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 1.1232e-06 - accuracy: 1.0000 - val_loss: 0.0634 - val_accuracy: 0.9806\n",
            "Epoch 47/50\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 9.2739e-07 - accuracy: 1.0000 - val_loss: 0.0633 - val_accuracy: 0.9806\n",
            "Epoch 48/50\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 8.2208e-07 - accuracy: 1.0000 - val_loss: 0.0631 - val_accuracy: 0.9806\n",
            "Epoch 49/50\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 1.1189e-06 - accuracy: 1.0000 - val_loss: 0.0631 - val_accuracy: 0.9806\n",
            "Epoch 50/50\n",
            "13/13 [==============================] - 0s 10ms/step - loss: 1.2477e-06 - accuracy: 1.0000 - val_loss: 0.0630 - val_accuracy: 0.9806\n",
            "Best epoch: 6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hypermodel = tuner.hypermodel.build(best_params)\n",
        "\n",
        "# Retrain the model\n",
        "hypermodel.fit(scaled_train, train_label, epochs=best_epoch, validation_split=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tPmffMQ9Zauc",
        "outputId": "17386cfc-8ad1-44cc-aefc-0fdb96b03b5c"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/6\n",
            "13/13 [==============================] - 4s 70ms/step - loss: 0.4011 - accuracy: 0.7995 - val_loss: 0.1036 - val_accuracy: 0.9612\n",
            "Epoch 2/6\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0678 - accuracy: 0.9804 - val_loss: 0.0668 - val_accuracy: 0.9806\n",
            "Epoch 3/6\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0212 - accuracy: 0.9951 - val_loss: 0.2511 - val_accuracy: 0.9417\n",
            "Epoch 4/6\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 0.0278 - accuracy: 0.9927 - val_loss: 0.3897 - val_accuracy: 0.9515\n",
            "Epoch 5/6\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 0.0314 - accuracy: 0.9902 - val_loss: 0.2734 - val_accuracy: 0.9515\n",
            "Epoch 6/6\n",
            "13/13 [==============================] - 0s 10ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.2306 - val_accuracy: 0.9417\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f246e6b2790>"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Employee:\n",
        "  def __init__(self, pay):\n",
        "    self.pay = pay\n",
        "\n",
        "  def Max(self):\n",
        "    max_pay = 2 * self.pay\n",
        "    return max_pay\n",
        "\n",
        "  def MaxMax(self):\n",
        "    return Employee.Max(self) * 3"
      ],
      "metadata": {
        "id": "zkDwJqQwYKVE"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "emp1 = Employee(5)\n",
        "emp1.MaxMax()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kyL8pH2tk27c",
        "outputId": "fc35fffa-63f5-4124-c8e0-c4f63e50bf76"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "30"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def layer_creation(model, nodes, rate, timesteps, nosamples):\n",
        "  for x in tf.range(len(nodes)):\n",
        "    if x == 0:\n",
        "      model.add(LSTM(units = nodes[x], activation = 'tanh', input_shape=(timesteps, nosamples), return_sequences = True))\n",
        "      model.add(Dropout(rate = rate))\n",
        "    elif x == len(nodes) - 1:\n",
        "      model.add(LSTM(units = nodes[x], activation = 'tanh', return_sequences = False))\n",
        "      model.add(Dropout(rate = rate))\n",
        "    else:\n",
        "      model.add(LSTM(units = nodes[x], activation = 'tanh', return_sequences = True))\n",
        "      model.add(Dropout(rate = rate))\n",
        "  return model"
      ],
      "metadata": {
        "id": "ROSvorUuI2an"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def LSTM_classifier(nodes, units, rate, learning_rate, timesteps = 8, nosamples = 64):\n",
        "\n",
        "#   model = Sequential()\n",
        "\n",
        "#   layer_creation(model, nodes, rate, timesteps, nosamples)\n",
        "  \n",
        "#   model.add(Flatten())\n",
        "  \n",
        "#   model.add(Dense(units = units))\n",
        "  \n",
        "#   model.add(Dropout(rate = rate))\n",
        "\n",
        "#   model.add(Dense(units = 2, activation = 'softmax'))\n",
        "\n",
        "#   model.compile(optimizer = Adam(learning_rate = learning_rate), loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
        "  \n",
        "#   return model\n",
        "\n",
        "# model = KerasClassifier(model = LSTM_classifier, verbose = 0)\n",
        "\n",
        "# model = KerasClassifier(model = LSTM_classifier, units = None, rate = None, nodes = None, learning_rate = None, batch_size = None, verbose = 0)\n",
        "\n",
        "# def hypertuning_lstm(estimator, param_distributions, n_iter, cv, X, y):\n",
        "#   rscv = RandomizedSearchCV(estimator = estimator, param_distributions = param_distributions, n_iter = n_iter, cv = cv, scoring = roc_auc_score(estimator, scaled_test, test_label))\n",
        "#   rscv.fit(X, y)\n",
        "#   ht_params = rscv.best_params_\n",
        "#   ht_score = rscv.best_score_\n",
        "\n",
        "#   return ht_params, ht_score\n",
        "\n",
        "# lstm_parameters, lstm_score = hypertuning_lstm(estimator = model, param_distributions = param_grid, cv = 3, X = scaled_train, y = train_label, n_iter = 60)\n",
        "# print(lstm_parameters, lstm_score)\n",
        "\n",
        "  # model = Sequential()\n",
        "  # model.add(LSTM(units = 64 , activation='tanh', input_shape=(timesteps, nosamples), return_sequences=True))\n",
        "  # model.add(Dropout(rate = 0.2))\n",
        "  # model.add(LSTM(units = 128, activation='tanh', return_sequences=True))\n",
        "  # model.add(Dropout(rate = 0.2))\n",
        "  # model.add(LSTM(units = 64, activation='tanh', return_sequences=False))\n",
        "  # model.add(Dropout(rate = 0.2))\n",
        "  # model.add(Flatten())\n",
        "  # model.add(Dense(units = 32))\n",
        "  # model.add(Dropout(rate = 0.2))\n",
        "  # model.add(Dense(units = 2, activation = 'softmax'))\n",
        "  # model.compile(optimizer = Adam(learning_rate = learning_rate), loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
        "  # return model"
      ],
      "metadata": {
        "id": "ABrLPf7C99Rg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model = KerasClassifier(build_fn = LSTM_classifier, batch_size = batch_size, epochs = epochs)\n",
        "# accuracies = cross_val_score(estimator = model, X = train, y = train_label, cv = KFold(3), n_jobs = -1)\n",
        "# np.mean(accuracies)\n",
        "# from sklearn.metrics import make_scorer\n",
        "# from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
        "# score = make_scorer(accuracy_score)\n",
        "# kfold_validation = KFold(3)\n",
        "# results = cross_val_score(model, train, train_label, cv = kfold_validation, scoring = score)\n",
        "# print(results)\n",
        "# print(np.mean(results))"
      ],
      "metadata": {
        "id": "ojwDBpaBht7U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(train, train_label, validation_split = 0.1,  batch_size = 64, epochs = epochs, verbose = 2, callbacks = [early_stopping])"
      ],
      "metadata": {
        "id": "jkpgK1bggYgC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model.predict(test, verbose = 1)\n",
        "predictions.shape"
      ],
      "metadata": {
        "id": "8cW2gOZ6hmTA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# q = np.concatenate((test_label[1:256], test_label[2048:2048+256]), axis = 0)"
      ],
      "metadata": {
        "id": "fbt0C_vkApWm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "ConfusionMatrixDisplay.from_predictions(test_label.argmax(axis = 1), np.round(predictions).argmax(axis = 1)) #with threshhold = 0.5\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "VYgxa1g9vQhR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can use ROC curve to find the **threshhold** that will give maximum accuracy i.e when **TPR** (True Positive Rate) is almost equal to **TNR** (True Negative Rate)"
      ],
      "metadata": {
        "id": "kPEaE4VmL-1C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "With threshold = 0.5, **TPR** = 244/(244 + 12) i.e. **0.953** and **TNR** = 247/(247 + 8) i.e. **0.968**"
      ],
      "metadata": {
        "id": "e4R6ahByNAOu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "weights_binary = model.get_weights()"
      ],
      "metadata": {
        "id": "NlsqX3gpM3or"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train_generator[0][0].shape"
      ],
      "metadata": {
        "id": "43keNIF1qfqp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train_generator[510][0]"
      ],
      "metadata": {
        "id": "cs5YRVgNqkVv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions"
      ],
      "metadata": {
        "id": "uB9rYMohrkTm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.count_nonzero(test_label.argmax(axis = 1))"
      ],
      "metadata": {
        "id": "aRcrqHYYx2Dd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "dGLvsyj29NXx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}